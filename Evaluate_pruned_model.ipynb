{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Evaluate pruned model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trantoai1/GraduatedProject/blob/main/Evaluate_pruned_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HimLIBrV0jC",
        "outputId": "891fd6ff-4935-4d76-9884-475d285c0aca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvstJwoz0Ecw",
        "outputId": "e8cf37de-8cf8-4bb1-af04-232e8837a748"
      },
      "source": [
        "%cd /content/drive/MyDrive/SSL/monodepth2\n",
        "from __future__ import absolute_import, division, print_function\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image as pil\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import time\n",
        "import networks\n",
        "from utils import download_model_if_doesnt_exist"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SSL/monodepth2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg6HqvI70Ecy"
      },
      "source": [
        "## Setting up network and loading weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phiBKODmJjQQ"
      },
      "source": [
        "pruned_name = \"models\"\n",
        "prunedpath = \"/content/drive/MyDrive/SSL/monodepth2/testprune/mono_640x192\"\n",
        "\n",
        "pruned_path = os.path.join(prunedpath, pruned_name, \"weights_1/encoder.pth\")\n",
        "# LOADING PRETRAINED MODEL\n",
        "pruned_model = networks.ResnetEncoder(18, False)\n",
        "loaded_dict_enc = torch.load(pruned_path, map_location='cpu')\n",
        "filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in pruned_model.state_dict()}\n",
        "pruned_model.load_state_dict(filtered_dict_enc)\n",
        "pruned_model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyLBJBw52_vg"
      },
      "source": [
        "model_name = \"mono_640x192\"\n",
        "modelpath = \"/content/drive/MyDrive/SSL/monodepth2/models\"\n",
        "encoder_path = os.path.join(modelpath, model_name, \"encoder.pth\")\n",
        "# LOADING PRETRAINED MODEL\n",
        "encoder = networks.ResnetEncoder(18, False)\n",
        "loaded_dict_enc = torch.load(encoder_path, map_location='cpu')\n",
        "filtered_dict_enc = {k: v for k, v in loaded_dict_enc.items() if k in encoder.state_dict()}\n",
        "encoder.load_state_dict(filtered_dict_enc)\n",
        "encoder.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB7dDToS0Ec0"
      },
      "source": [
        "## Loading the test image and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyxk9gYi0Ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364d989b-e97f-4a70-cefb-a34a6d75b9cd"
      },
      "source": [
        "total = 0\n",
        "zeros = 0\n",
        "for m in encoder.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        total += m.weight.data.numel()\n",
        "        weight_copy = m.weight.data.abs().clone()\n",
        "        mask = weight_copy.gt(0).float()\n",
        "        zeros = zeros + mask.numel() - torch.sum(mask)\n",
        "print('total number weight:{}'.format(total))\n",
        "print('total zeros weight:{}'.format(zeros))\n",
        "print('total remain weight:{}'.format(total-zeros))\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number weight:11166912\n",
            "total zeros weight:0.0\n",
            "total remain weight:11166912.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00211e9b-08bb-432d-b138-86fed03d5911",
        "id": "vwofK2xZX9b1"
      },
      "source": [
        "total = 0\n",
        "pruned = 0\n",
        "for m in pruned_model.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        total += m.weight.data.numel()\n",
        "        weight_copy = m.weight.data.abs().clone()\n",
        "        mask = weight_copy.gt(0).float()\n",
        "        pruned = pruned + mask.numel() - torch.sum(mask)\n",
        "print('total number weight:{}'.format(total))\n",
        "print('total zeros weight:{}'.format(pruned))\n",
        "print('total remain weight:{}'.format(total-pruned))\n",
        "print('Pruned rate:%2f'% (100*int(pruned.item())/total))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number weight:11166912\n",
            "total zeros weight:10776676.0\n",
            "total remain weight:390236.0\n",
            "Pruned rate:96.505426\n"
          ]
        }
      ]
    }
  ]
}