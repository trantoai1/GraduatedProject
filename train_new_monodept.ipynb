{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train new monodept.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOM/27EIMoxHU6FGRB00L4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trantoai1/GraduatedProject/blob/main/train_new_monodept.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui6kQPHkPsJH",
        "outputId": "a7c67348-20ad-4c26-d291-e4cd437b56ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xK-Xo_SFOWk"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEUYMtKsw-u2"
      },
      "source": [
        "!add-apt-repository ppa:deadsnakes/ppa\n",
        "!apt-get update\n",
        "!apt-get install python3.6\n",
        "!apt-get install python3.6-dev\n",
        "\n",
        "!wget https://bootstrap.pypa.io/get-pip.py && python3.6 get-pip.py\n",
        "  \n",
        "import sys\n",
        "\n",
        "sys.path[2] = '/usr/lib/python36.zip'\n",
        "sys.path[3] = '/usr/lib/python3.6'\n",
        "sys.path[4] = '/usr/lib/python3.6/lib-dynload'\n",
        "sys.path[5] = '/usr/local/lib/python3.6/dist-packages'\n",
        "sys.path[7] ='/usr/local/lib/python3.6/dist-packages/IPython/extensions'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p9KOJzdZyho"
      },
      "source": [
        "!python3.6 -m pip install torch==0.4.1\n",
        "!python3.6 -m pip install scikit-image\n",
        "!python3.6 -m pip install tensorboardX==1.4\n",
        "!python3.6 -m pip install torchvision==0.2.1\n",
        "!python3.6 -m pip install opencv-python==3.4.0.14\n",
        "!python3.6 -m pip install numpy\n",
        "!python3.6 -m pip install IPython\n",
        "!python3.6 -m pip install ipykernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToGg0oTv2mz6"
      },
      "source": [
        "!rm -rf /content/drive/MyDrive/SSL/monodepth2/test\n",
        "!rm -rf /content/drive/MyDrive/SSL/monodepth2/retrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jS6F-UPHBzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a280f1-6751-4ea8-ddfe-d20ef881a364"
      },
      "source": [
        "%cd /content/drive/MyDrive/SSL/monodepth2\n",
        "# !python3.6 train.py --model_name mono_model --png --log_dir benchmark  --num_epochs 1  --split benchmark \n",
        "!python3.6 train.py --model_name mono_model --png --log_dir test  --num_epochs 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SSL/monodepth2\n",
            "Training model named:\n",
            "   mono_model\n",
            "Models and tensorboard events files are saved to:\n",
            "   test\n",
            "Training is using:\n",
            "   cuda\n",
            "Using split:\n",
            "   eigen_zhou\n",
            "There are 1000 training items and 4424 validation items\n",
            "\n",
            "Using mask:\n",
            "   magnitude\n",
            "Removing biases...\n",
            "Removed 21 layers.\n",
            "Removing 2D batch norms...\n",
            "Removing encoder.bn1 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.0.bn1 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.0.bn2 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.1.bn1 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.1.bn2 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer2.0.bn1 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.0.bn2 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.0.downsample.1 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.1.bn1 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.1.bn2 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer3.0.bn1 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.0.bn2 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.0.downsample.1 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.1.bn1 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.1.bn2 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer4.0.bn1 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.0.bn2 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.0.downsample.1 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.1.bn1 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.1.bn2 of size torch.Size([512]) = 512 parameters.\n",
            "Removing 1D batch norms...\n",
            "encoder.conv1.weight 459\n",
            "encoder.layer1.0.conv1.weight 1839\n",
            "encoder.layer1.0.conv2.weight 1905\n",
            "encoder.layer1.1.conv1.weight 1839\n",
            "encoder.layer1.1.conv2.weight 1851\n",
            "encoder.layer2.0.conv1.weight 3701\n",
            "encoder.layer2.0.conv2.weight 7359\n",
            "encoder.layer2.0.downsample.0.weight 413\n",
            "encoder.layer2.1.conv1.weight 7265\n",
            "encoder.layer2.1.conv2.weight 7491\n",
            "encoder.layer3.0.conv1.weight 14614\n",
            "encoder.layer3.0.conv2.weight 29604\n",
            "encoder.layer3.0.downsample.0.weight 1617\n",
            "encoder.layer3.1.conv1.weight 29213\n",
            "encoder.layer3.1.conv2.weight 29868\n",
            "encoder.layer4.0.conv1.weight 59080\n",
            "encoder.layer4.0.conv2.weight 117727\n",
            "encoder.layer4.0.downsample.0.weight 6618\n",
            "encoder.layer4.1.conv1.weight 117590\n",
            "encoder.layer4.1.conv2.weight 118227\n",
            "encoder.fc.weight 25394\n",
            "Prune rate: 0.5\n",
            "\n",
            "Total Model parameters: 11689512\n",
            "Total parameters after removed layers: 11678912\n",
            "Total parameters under sparsity level of 0.05: 583945.6\n",
            "Training\n",
            "epoch   0 | batch      0 | examples/s:   3.2 | loss: 0.16290 | time elapsed: 00h00m57s | time left: 00h00m00s\n",
            "epoch   0 | batch      0 | examples/s:   3.2 | loss: 0.16290 | time elapsed: 00h00m57s | time left: 00h00m00s\n",
            "epoch   0 | batch      1 | examples/s:  17.4 | loss: 0.15600 | time elapsed: 00h01m23s | time left: 01h54m22s\n",
            "epoch   0 | batch      2 | examples/s:  15.0 | loss: 0.16895 | time elapsed: 00h01m24s | time left: 00h57m05s\n",
            "epoch   0 | batch      3 | examples/s:  12.6 | loss: 0.17156 | time elapsed: 00h01m25s | time left: 00h38m03s\n",
            "epoch   0 | batch      4 | examples/s:  12.1 | loss: 0.15667 | time elapsed: 00h01m26s | time left: 00h28m32s\n",
            "epoch   0 | batch      5 | examples/s:  12.6 | loss: 0.14500 | time elapsed: 00h01m27s | time left: 00h22m49s\n",
            "epoch   0 | batch      6 | examples/s:  11.1 | loss: 0.17913 | time elapsed: 00h01m28s | time left: 00h19m01s\n",
            "epoch   0 | batch      7 | examples/s:   9.9 | loss: 0.15299 | time elapsed: 00h01m30s | time left: 00h16m20s\n",
            "epoch   0 | batch      8 | examples/s:   7.9 | loss: 0.15448 | time elapsed: 00h01m31s | time left: 00h14m21s\n",
            "epoch   0 | batch      9 | examples/s:   7.8 | loss: 0.14415 | time elapsed: 00h01m33s | time left: 00h12m49s\n",
            "epoch   0 | batch     10 | examples/s:   7.4 | loss: 0.14680 | time elapsed: 00h01m35s | time left: 00h11m35s\n",
            "epoch   0 | batch     11 | examples/s:   7.1 | loss: 0.15834 | time elapsed: 00h01m37s | time left: 00h10m35s\n",
            "epoch   0 | batch     12 | examples/s:   7.5 | loss: 0.17196 | time elapsed: 00h01m38s | time left: 00h09m44s\n",
            "epoch   0 | batch     13 | examples/s:   7.4 | loss: 0.15237 | time elapsed: 00h01m40s | time left: 00h09m01s\n",
            "epoch   0 | batch     14 | examples/s:   8.4 | loss: 0.16516 | time elapsed: 00h01m42s | time left: 00h08m22s\n",
            "epoch   0 | batch     15 | examples/s:   7.2 | loss: 0.15234 | time elapsed: 00h01m43s | time left: 00h07m50s\n",
            "epoch   0 | batch     16 | examples/s:   6.3 | loss: 0.14894 | time elapsed: 00h01m45s | time left: 00h07m23s\n",
            "epoch   0 | batch     17 | examples/s:   7.4 | loss: 0.14784 | time elapsed: 00h01m47s | time left: 00h06m57s\n",
            "epoch   0 | batch     18 | examples/s:   6.6 | loss: 0.16642 | time elapsed: 00h01m49s | time left: 00h06m35s\n",
            "epoch   0 | batch     19 | examples/s:   8.5 | loss: 0.15395 | time elapsed: 00h01m50s | time left: 00h06m13s\n",
            "epoch   0 | batch     20 | examples/s:   6.7 | loss: 0.16360 | time elapsed: 00h01m52s | time left: 00h05m55s\n",
            "epoch   0 | batch     21 | examples/s:   7.9 | loss: 0.16368 | time elapsed: 00h01m54s | time left: 00h05m37s\n",
            "epoch   0 | batch     22 | examples/s:   6.8 | loss: 0.16720 | time elapsed: 00h01m56s | time left: 00h05m22s\n",
            "epoch   0 | batch     23 | examples/s:   6.6 | loss: 0.15428 | time elapsed: 00h01m58s | time left: 00h05m08s\n",
            "epoch   0 | batch     24 | examples/s:   7.6 | loss: 0.15180 | time elapsed: 00h01m59s | time left: 00h04m54s\n",
            "epoch   0 | batch     25 | examples/s:   7.3 | loss: 0.15093 | time elapsed: 00h02m01s | time left: 00h04m42s\n",
            "epoch   0 | batch     26 | examples/s:   6.3 | loss: 0.14366 | time elapsed: 00h02m03s | time left: 00h04m31s\n",
            "epoch   0 | batch     27 | examples/s:   6.7 | loss: 0.14520 | time elapsed: 00h02m05s | time left: 00h04m20s\n",
            "epoch   0 | batch     28 | examples/s:   7.1 | loss: 0.13302 | time elapsed: 00h02m07s | time left: 00h04m10s\n",
            "epoch   0 | batch     29 | examples/s:   7.0 | loss: 0.14522 | time elapsed: 00h02m09s | time left: 00h04m00s\n",
            "epoch   0 | batch     30 | examples/s:   7.3 | loss: 0.14577 | time elapsed: 00h02m11s | time left: 00h03m51s\n",
            "epoch   0 | batch     31 | examples/s:   6.6 | loss: 0.16095 | time elapsed: 00h02m12s | time left: 00h03m42s\n",
            "epoch   0 | batch     32 | examples/s:   6.1 | loss: 0.14636 | time elapsed: 00h02m14s | time left: 00h03m35s\n",
            "epoch   0 | batch     33 | examples/s:   7.8 | loss: 0.16594 | time elapsed: 00h02m16s | time left: 00h03m27s\n",
            "epoch   0 | batch     34 | examples/s:   6.7 | loss: 0.15112 | time elapsed: 00h02m18s | time left: 00h03m19s\n",
            "epoch   0 | batch     35 | examples/s:   6.5 | loss: 0.14701 | time elapsed: 00h02m20s | time left: 00h03m12s\n",
            "epoch   0 | batch     36 | examples/s:   6.9 | loss: 0.13859 | time elapsed: 00h02m22s | time left: 00h03m05s\n",
            "epoch   0 | batch     37 | examples/s:   7.6 | loss: 0.15195 | time elapsed: 00h02m24s | time left: 00h02m59s\n",
            "epoch   0 | batch     38 | examples/s:   6.4 | loss: 0.14642 | time elapsed: 00h02m25s | time left: 00h02m52s\n",
            "epoch   0 | batch     39 | examples/s:   7.5 | loss: 0.15134 | time elapsed: 00h02m27s | time left: 00h02m46s\n",
            "epoch   0 | batch     40 | examples/s:   6.6 | loss: 0.13583 | time elapsed: 00h02m29s | time left: 00h02m40s\n",
            "epoch   0 | batch     41 | examples/s:   6.7 | loss: 0.13494 | time elapsed: 00h02m31s | time left: 00h02m35s\n",
            "epoch   0 | batch     42 | examples/s:   6.8 | loss: 0.12975 | time elapsed: 00h02m33s | time left: 00h02m29s\n",
            "epoch   0 | batch     43 | examples/s:   7.8 | loss: 0.14766 | time elapsed: 00h02m35s | time left: 00h02m24s\n",
            "epoch   0 | batch     44 | examples/s:   6.5 | loss: 0.14332 | time elapsed: 00h02m37s | time left: 00h02m19s\n",
            "epoch   0 | batch     45 | examples/s:   6.1 | loss: 0.15576 | time elapsed: 00h02m39s | time left: 00h02m14s\n",
            "epoch   0 | batch     46 | examples/s:   7.4 | loss: 0.14664 | time elapsed: 00h02m40s | time left: 00h02m09s\n",
            "epoch   0 | batch     47 | examples/s:   7.0 | loss: 0.13540 | time elapsed: 00h02m42s | time left: 00h02m04s\n",
            "epoch   0 | batch     48 | examples/s:   7.9 | loss: 0.15702 | time elapsed: 00h02m44s | time left: 00h01m59s\n",
            "epoch   0 | batch     49 | examples/s:   6.7 | loss: 0.14968 | time elapsed: 00h02m46s | time left: 00h01m55s\n",
            "epoch   0 | batch     50 | examples/s:   6.4 | loss: 0.15978 | time elapsed: 00h02m48s | time left: 00h01m50s\n",
            "epoch   0 | batch     51 | examples/s:   7.4 | loss: 0.11521 | time elapsed: 00h02m49s | time left: 00h01m46s\n",
            "epoch   0 | batch     52 | examples/s:   6.2 | loss: 0.17171 | time elapsed: 00h02m51s | time left: 00h01m42s\n",
            "epoch   0 | batch     53 | examples/s:   7.0 | loss: 0.14771 | time elapsed: 00h02m53s | time left: 00h01m38s\n",
            "epoch   0 | batch     54 | examples/s:   8.8 | loss: 0.13897 | time elapsed: 00h02m55s | time left: 00h01m34s\n",
            "epoch   0 | batch     55 | examples/s:   7.0 | loss: 0.16011 | time elapsed: 00h02m56s | time left: 00h01m30s\n",
            "epoch   0 | batch     56 | examples/s:   6.0 | loss: 0.15773 | time elapsed: 00h02m59s | time left: 00h01m26s\n",
            "epoch   0 | batch     57 | examples/s:   6.9 | loss: 0.17174 | time elapsed: 00h03m00s | time left: 00h01m22s\n",
            "epoch   0 | batch     58 | examples/s:   6.3 | loss: 0.14402 | time elapsed: 00h03m02s | time left: 00h01m18s\n",
            "epoch   0 | batch     59 | examples/s:   6.7 | loss: 0.14965 | time elapsed: 00h03m04s | time left: 00h01m15s\n",
            "epoch   0 | batch     60 | examples/s:   6.4 | loss: 0.15543 | time elapsed: 00h03m06s | time left: 00h01m11s\n",
            "epoch   0 | batch     61 | examples/s:   6.7 | loss: 0.14426 | time elapsed: 00h03m08s | time left: 00h01m08s\n",
            "epoch   0 | batch     62 | examples/s:   8.5 | loss: 0.14362 | time elapsed: 00h03m10s | time left: 00h01m04s\n",
            "epoch   0 | batch     63 | examples/s:   8.7 | loss: 0.15224 | time elapsed: 00h03m11s | time left: 00h01m00s\n",
            "epoch   0 | batch     64 | examples/s:   8.9 | loss: 0.13322 | time elapsed: 00h03m13s | time left: 00h00m57s\n",
            "epoch   0 | batch     65 | examples/s:  10.3 | loss: 0.15284 | time elapsed: 00h03m14s | time left: 00h00m53s\n",
            "epoch   0 | batch     66 | examples/s:  10.8 | loss: 0.13036 | time elapsed: 00h03m15s | time left: 00h00m50s\n",
            "epoch   0 | batch     67 | examples/s:  12.1 | loss: 0.14615 | time elapsed: 00h03m16s | time left: 00h00m46s\n",
            "epoch   0 | batch     68 | examples/s:  15.5 | loss: 0.15663 | time elapsed: 00h03m17s | time left: 00h00m43s\n",
            "epoch   0 | batch     69 | examples/s:  18.1 | loss: 0.15272 | time elapsed: 00h03m18s | time left: 00h00m40s\n",
            "epoch   0 | batch     70 | examples/s:  18.1 | loss: 0.14973 | time elapsed: 00h03m19s | time left: 00h00m36s\n",
            "epoch   0 | batch     71 | examples/s:  18.2 | loss: 0.14727 | time elapsed: 00h03m19s | time left: 00h00m33s\n",
            "epoch   0 | batch     72 | examples/s:  18.2 | loss: 0.14995 | time elapsed: 00h03m20s | time left: 00h00m30s\n",
            "epoch   0 | batch     73 | examples/s:  18.2 | loss: 0.15687 | time elapsed: 00h03m21s | time left: 00h00m27s\n",
            "epoch   0 | batch     74 | examples/s:  18.3 | loss: 0.14961 | time elapsed: 00h03m22s | time left: 00h00m24s\n",
            "epoch   0 | batch     75 | examples/s:  18.0 | loss: 0.13749 | time elapsed: 00h03m22s | time left: 00h00m21s\n",
            "epoch   0 | batch     76 | examples/s:  17.9 | loss: 0.14416 | time elapsed: 00h03m23s | time left: 00h00m18s\n",
            "epoch   0 | batch     77 | examples/s:  18.1 | loss: 0.16317 | time elapsed: 00h03m24s | time left: 00h00m15s\n",
            "epoch   0 | batch     78 | examples/s:  18.2 | loss: 0.14947 | time elapsed: 00h03m25s | time left: 00h00m13s\n",
            "epoch   0 | batch     79 | examples/s:  18.1 | loss: 0.16010 | time elapsed: 00h03m25s | time left: 00h00m10s\n",
            "epoch   0 | batch     80 | examples/s:  18.2 | loss: 0.14638 | time elapsed: 00h03m26s | time left: 00h00m07s\n",
            "epoch   0 | batch     81 | examples/s:  18.1 | loss: 0.13532 | time elapsed: 00h03m27s | time left: 00h00m05s\n",
            "epoch   0 | batch     82 | examples/s:  18.0 | loss: 0.14222 | time elapsed: 00h03m28s | time left: 00h00m02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uprK_F0JfwN4",
        "outputId": "6b2c0fa6-6e5b-4995-d042-962f25efc62c"
      },
      "source": [
        "%cd /content/drive/MyDrive/SSL/monodepth2\n",
        "!python3.6 train.py --model_name mono_model --png --log_dir retrain  --num_epochs 1 --load_weights_folder test/mono_model/pruned/weights_0/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SSL/monodepth2\n",
            "Training model named:\n",
            "   mono_model\n",
            "Models and tensorboard events files are saved to:\n",
            "   retrain\n",
            "Training is using:\n",
            "   cuda\n",
            "loading model from folder test/mono_model/pruned/weights_0/\n",
            "Loading encoder weights...\n",
            "Loading depth weights...\n",
            "Loading pose_encoder weights...\n",
            "Loading pose weights...\n",
            "test/mono_model/pruned/weights_0/adam.pth\n",
            "Loading Adam weights\n",
            "Using split:\n",
            "   eigen_zhou\n",
            "There are 1000 training items and 4424 validation items\n",
            "\n",
            "Using mask:\n",
            "   magnitude\n",
            "Removing biases...\n",
            "Removed 21 layers.\n",
            "Removing 2D batch norms...\n",
            "Removing encoder.bn1 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.0.bn1 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.0.bn2 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.1.bn1 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer1.1.bn2 of size torch.Size([64]) = 64 parameters.\n",
            "Removing encoder.layer2.0.bn1 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.0.bn2 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.0.downsample.1 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.1.bn1 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer2.1.bn2 of size torch.Size([128]) = 128 parameters.\n",
            "Removing encoder.layer3.0.bn1 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.0.bn2 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.0.downsample.1 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.1.bn1 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer3.1.bn2 of size torch.Size([256]) = 256 parameters.\n",
            "Removing encoder.layer4.0.bn1 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.0.bn2 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.0.downsample.1 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.1.bn1 of size torch.Size([512]) = 512 parameters.\n",
            "Removing encoder.layer4.1.bn2 of size torch.Size([512]) = 512 parameters.\n",
            "Removing 1D batch norms...\n",
            "encoder.conv1.weight 490\n",
            "encoder.layer1.0.conv1.weight 1850\n",
            "encoder.layer1.0.conv2.weight 1922\n",
            "encoder.layer1.1.conv1.weight 1844\n",
            "encoder.layer1.1.conv2.weight 1893\n",
            "encoder.layer2.0.conv1.weight 3649\n",
            "encoder.layer2.0.conv2.weight 7523\n",
            "encoder.layer2.0.downsample.0.weight 428\n",
            "encoder.layer2.1.conv1.weight 7371\n",
            "encoder.layer2.1.conv2.weight 7397\n",
            "encoder.layer3.0.conv1.weight 14582\n",
            "encoder.layer3.0.conv2.weight 29802\n",
            "encoder.layer3.0.downsample.0.weight 1623\n",
            "encoder.layer3.1.conv1.weight 29465\n",
            "encoder.layer3.1.conv2.weight 29564\n",
            "encoder.layer4.0.conv1.weight 58526\n",
            "encoder.layer4.0.conv2.weight 117957\n",
            "encoder.layer4.0.downsample.0.weight 6565\n",
            "encoder.layer4.1.conv1.weight 117443\n",
            "encoder.layer4.1.conv2.weight 117827\n",
            "encoder.fc.weight 25702\n",
            "Prune rate: 0.5\n",
            "\n",
            "Total Model parameters: 11689512\n",
            "Total parameters after removed layers: 11678912\n",
            "Total parameters under sparsity level of 0.05: 583945.6\n",
            "Training\n",
            "epoch   0 | batch      0 | examples/s:   4.8 | loss: 0.13081 | time elapsed: 00h00m31s | time left: 00h00m00s\n",
            "epoch   0 | batch      0 | examples/s:   4.8 | loss: 0.13081 | time elapsed: 00h00m31s | time left: 00h00m00s\n",
            "epoch   0 | batch      1 | examples/s:  10.1 | loss: 0.16324 | time elapsed: 00h01m09s | time left: 01h34m33s\n",
            "epoch   0 | batch      2 | examples/s:  11.1 | loss: 0.15336 | time elapsed: 00h01m10s | time left: 00h47m30s\n",
            "epoch   0 | batch      3 | examples/s:  13.6 | loss: 0.15426 | time elapsed: 00h01m11s | time left: 00h31m42s\n",
            "epoch   0 | batch      4 | examples/s:  11.3 | loss: 0.15405 | time elapsed: 00h01m12s | time left: 00h23m52s\n",
            "epoch   0 | batch      5 | examples/s:   9.8 | loss: 0.15679 | time elapsed: 00h01m13s | time left: 00h19m12s\n",
            "epoch   0 | batch      6 | examples/s:  10.7 | loss: 0.15042 | time elapsed: 00h01m15s | time left: 00h16m03s\n",
            "epoch   0 | batch      7 | examples/s:   6.6 | loss: 0.14307 | time elapsed: 00h01m17s | time left: 00h13m56s\n",
            "epoch   0 | batch      8 | examples/s:   8.4 | loss: 0.15636 | time elapsed: 00h01m18s | time left: 00h12m16s\n",
            "epoch   0 | batch      9 | examples/s:   8.4 | loss: 0.14376 | time elapsed: 00h01m20s | time left: 00h10m58s\n",
            "epoch   0 | batch     10 | examples/s:   6.1 | loss: 0.14859 | time elapsed: 00h01m22s | time left: 00h09m59s\n",
            "epoch   0 | batch     11 | examples/s:   7.5 | loss: 0.13323 | time elapsed: 00h01m23s | time left: 00h09m08s\n",
            "epoch   0 | batch     12 | examples/s:   6.4 | loss: 0.12893 | time elapsed: 00h01m25s | time left: 00h08m27s\n",
            "epoch   0 | batch     13 | examples/s:   5.4 | loss: 0.14759 | time elapsed: 00h01m28s | time left: 00h07m54s\n",
            "epoch   0 | batch     14 | examples/s:   8.5 | loss: 0.15370 | time elapsed: 00h01m29s | time left: 00h07m21s\n",
            "epoch   0 | batch     15 | examples/s:   7.5 | loss: 0.13682 | time elapsed: 00h01m31s | time left: 00h06m54s\n",
            "epoch   0 | batch     16 | examples/s:   6.6 | loss: 0.13892 | time elapsed: 00h01m33s | time left: 00h06m30s\n",
            "epoch   0 | batch     17 | examples/s:   6.9 | loss: 0.14739 | time elapsed: 00h01m35s | time left: 00h06m09s\n",
            "epoch   0 | batch     18 | examples/s:   6.5 | loss: 0.13411 | time elapsed: 00h01m37s | time left: 00h05m50s\n",
            "epoch   0 | batch     19 | examples/s:   6.2 | loss: 0.14155 | time elapsed: 00h01m39s | time left: 00h05m34s\n",
            "epoch   0 | batch     20 | examples/s:   6.5 | loss: 0.15261 | time elapsed: 00h01m41s | time left: 00h05m18s\n",
            "epoch   0 | batch     21 | examples/s:   5.8 | loss: 0.15293 | time elapsed: 00h01m43s | time left: 00h05m05s\n",
            "epoch   0 | batch     22 | examples/s:   7.2 | loss: 0.13173 | time elapsed: 00h01m45s | time left: 00h04m51s\n",
            "epoch   0 | batch     23 | examples/s:   6.1 | loss: 0.16023 | time elapsed: 00h01m47s | time left: 00h04m39s\n",
            "epoch   0 | batch     24 | examples/s:   5.9 | loss: 0.12435 | time elapsed: 00h01m49s | time left: 00h04m28s\n",
            "epoch   0 | batch     25 | examples/s:   6.8 | loss: 0.15100 | time elapsed: 00h01m51s | time left: 00h04m17s\n",
            "epoch   0 | batch     26 | examples/s:   5.7 | loss: 0.14144 | time elapsed: 00h01m53s | time left: 00h04m08s\n",
            "epoch   0 | batch     27 | examples/s:   7.3 | loss: 0.12513 | time elapsed: 00h01m55s | time left: 00h03m58s\n",
            "epoch   0 | batch     28 | examples/s:   7.2 | loss: 0.16134 | time elapsed: 00h01m56s | time left: 00h03m49s\n",
            "epoch   0 | batch     29 | examples/s:   6.9 | loss: 0.14512 | time elapsed: 00h01m58s | time left: 00h03m41s\n",
            "epoch   0 | batch     30 | examples/s:   7.2 | loss: 0.14391 | time elapsed: 00h02m00s | time left: 00h03m32s\n",
            "epoch   0 | batch     31 | examples/s:   7.9 | loss: 0.17111 | time elapsed: 00h02m02s | time left: 00h03m24s\n",
            "epoch   0 | batch     32 | examples/s:   5.5 | loss: 0.14978 | time elapsed: 00h02m04s | time left: 00h03m18s\n",
            "epoch   0 | batch     33 | examples/s:   6.2 | loss: 0.14263 | time elapsed: 00h02m06s | time left: 00h03m11s\n",
            "epoch   0 | batch     34 | examples/s:   6.2 | loss: 0.14161 | time elapsed: 00h02m08s | time left: 00h03m05s\n",
            "epoch   0 | batch     35 | examples/s:   6.4 | loss: 0.13950 | time elapsed: 00h02m10s | time left: 00h02m58s\n",
            "epoch   0 | batch     36 | examples/s:   4.8 | loss: 0.13645 | time elapsed: 00h02m13s | time left: 00h02m53s\n",
            "epoch   0 | batch     37 | examples/s:   6.3 | loss: 0.14836 | time elapsed: 00h02m15s | time left: 00h02m47s\n",
            "epoch   0 | batch     38 | examples/s:   6.7 | loss: 0.15166 | time elapsed: 00h02m17s | time left: 00h02m42s\n",
            "epoch   0 | batch     39 | examples/s:   6.1 | loss: 0.14796 | time elapsed: 00h02m19s | time left: 00h02m36s\n",
            "epoch   0 | batch     40 | examples/s:   6.4 | loss: 0.14177 | time elapsed: 00h02m21s | time left: 00h02m31s\n",
            "epoch   0 | batch     41 | examples/s:   6.4 | loss: 0.15016 | time elapsed: 00h02m23s | time left: 00h02m26s\n",
            "epoch   0 | batch     42 | examples/s:   6.4 | loss: 0.13494 | time elapsed: 00h02m25s | time left: 00h02m21s\n",
            "epoch   0 | batch     43 | examples/s:   6.6 | loss: 0.13680 | time elapsed: 00h02m26s | time left: 00h02m16s\n",
            "epoch   0 | batch     44 | examples/s:   5.9 | loss: 0.14198 | time elapsed: 00h02m29s | time left: 00h02m12s\n",
            "epoch   0 | batch     45 | examples/s:   6.5 | loss: 0.16532 | time elapsed: 00h02m31s | time left: 00h02m07s\n",
            "epoch   0 | batch     46 | examples/s:   6.4 | loss: 0.14140 | time elapsed: 00h02m33s | time left: 00h02m03s\n",
            "epoch   0 | batch     47 | examples/s:   6.5 | loss: 0.15184 | time elapsed: 00h02m35s | time left: 00h01m58s\n",
            "epoch   0 | batch     48 | examples/s:   6.4 | loss: 0.15984 | time elapsed: 00h02m37s | time left: 00h01m54s\n",
            "epoch   0 | batch     49 | examples/s:   5.6 | loss: 0.14214 | time elapsed: 00h02m39s | time left: 00h01m50s\n",
            "epoch   0 | batch     50 | examples/s:   6.6 | loss: 0.14643 | time elapsed: 00h02m41s | time left: 00h01m46s\n",
            "epoch   0 | batch     51 | examples/s:   7.2 | loss: 0.13900 | time elapsed: 00h02m42s | time left: 00h01m42s\n",
            "epoch   0 | batch     52 | examples/s:   5.8 | loss: 0.16000 | time elapsed: 00h02m45s | time left: 00h01m38s\n",
            "epoch   0 | batch     53 | examples/s:   6.0 | loss: 0.14186 | time elapsed: 00h02m47s | time left: 00h01m34s\n",
            "epoch   0 | batch     54 | examples/s:   5.4 | loss: 0.13879 | time elapsed: 00h02m49s | time left: 00h01m31s\n",
            "epoch   0 | batch     55 | examples/s:   6.8 | loss: 0.16592 | time elapsed: 00h02m51s | time left: 00h01m27s\n",
            "epoch   0 | batch     56 | examples/s:   6.0 | loss: 0.16589 | time elapsed: 00h02m53s | time left: 00h01m23s\n",
            "epoch   0 | batch     57 | examples/s:   6.6 | loss: 0.14914 | time elapsed: 00h02m55s | time left: 00h01m20s\n",
            "epoch   0 | batch     58 | examples/s:   6.2 | loss: 0.14051 | time elapsed: 00h02m57s | time left: 00h01m16s\n",
            "epoch   0 | batch     59 | examples/s:   6.4 | loss: 0.15487 | time elapsed: 00h02m59s | time left: 00h01m13s\n",
            "epoch   0 | batch     60 | examples/s:   5.7 | loss: 0.15060 | time elapsed: 00h03m01s | time left: 00h01m09s\n",
            "epoch   0 | batch     61 | examples/s:   6.5 | loss: 0.16472 | time elapsed: 00h03m03s | time left: 00h01m06s\n",
            "epoch   0 | batch     62 | examples/s:   6.8 | loss: 0.15255 | time elapsed: 00h03m05s | time left: 00h01m02s\n",
            "epoch   0 | batch     63 | examples/s:   5.7 | loss: 0.16042 | time elapsed: 00h03m07s | time left: 00h00m59s\n",
            "epoch   0 | batch     64 | examples/s:   9.0 | loss: 0.14160 | time elapsed: 00h03m09s | time left: 00h00m56s\n",
            "epoch   0 | batch     65 | examples/s:   7.3 | loss: 0.15773 | time elapsed: 00h03m11s | time left: 00h00m52s\n",
            "epoch   0 | batch     66 | examples/s:   9.1 | loss: 0.13836 | time elapsed: 00h03m12s | time left: 00h00m49s\n",
            "epoch   0 | batch     67 | examples/s:   8.4 | loss: 0.15739 | time elapsed: 00h03m13s | time left: 00h00m46s\n",
            "epoch   0 | batch     68 | examples/s:   9.0 | loss: 0.14309 | time elapsed: 00h03m15s | time left: 00h00m43s\n",
            "epoch   0 | batch     69 | examples/s:   9.6 | loss: 0.15680 | time elapsed: 00h03m16s | time left: 00h00m39s\n",
            "epoch   0 | batch     70 | examples/s:  11.0 | loss: 0.13932 | time elapsed: 00h03m17s | time left: 00h00m36s\n",
            "epoch   0 | batch     71 | examples/s:  12.6 | loss: 0.13506 | time elapsed: 00h03m18s | time left: 00h00m33s\n",
            "epoch   0 | batch     72 | examples/s:  14.2 | loss: 0.16373 | time elapsed: 00h03m19s | time left: 00h00m30s\n",
            "epoch   0 | batch     73 | examples/s:  16.9 | loss: 0.15072 | time elapsed: 00h03m20s | time left: 00h00m27s\n",
            "epoch   0 | batch     74 | examples/s:  17.8 | loss: 0.13009 | time elapsed: 00h03m21s | time left: 00h00m24s\n",
            "epoch   0 | batch     75 | examples/s:  18.3 | loss: 0.13824 | time elapsed: 00h03m22s | time left: 00h00m21s\n",
            "epoch   0 | batch     76 | examples/s:  18.0 | loss: 0.14361 | time elapsed: 00h03m23s | time left: 00h00m18s\n",
            "epoch   0 | batch     77 | examples/s:  18.0 | loss: 0.13800 | time elapsed: 00h03m23s | time left: 00h00m15s\n",
            "epoch   0 | batch     78 | examples/s:  17.9 | loss: 0.14576 | time elapsed: 00h03m24s | time left: 00h00m13s\n",
            "epoch   0 | batch     79 | examples/s:  18.3 | loss: 0.14739 | time elapsed: 00h03m25s | time left: 00h00m10s\n",
            "epoch   0 | batch     80 | examples/s:  17.0 | loss: 0.15600 | time elapsed: 00h03m26s | time left: 00h00m07s\n",
            "epoch   0 | batch     81 | examples/s:  18.2 | loss: 0.16372 | time elapsed: 00h03m26s | time left: 00h00m05s\n",
            "epoch   0 | batch     82 | examples/s:  17.7 | loss: 0.15064 | time elapsed: 00h03m27s | time left: 00h00m02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUygd_XtuzSM"
      },
      "source": [
        "!pip install expecttest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZcd9w9TvILb"
      },
      "source": [
        "!cp /content/drive/MyDrive/SSL/monodepth2/newmodel/mono_model/models/weights_0/*.pth /content/drive/MyDrive/SSL/monodepth2/models/mono_no_pt_640x192"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}